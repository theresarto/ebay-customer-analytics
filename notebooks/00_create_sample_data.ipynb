{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac3c34b",
   "metadata": {},
   "source": [
    "# Create Anonymised Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b6f42",
   "metadata": {},
   "source": [
    "This notebook creates a privacy-protected sample of the eBay sales data for portfolio sharing.\n",
    "\n",
    "**Purpose:**\n",
    "- Protect business-sensitive information\n",
    "- Create reproducible sample for public GitHub repository\n",
    "- Maintain data distributions for meaningful analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce802bb8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c996443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd50d64",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed26184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATA_PATH = '../data/raw/'\n",
    "OUTPUT_PATH = '../data/'\n",
    "\n",
    "# Sampling parameters\n",
    "SAMPLE_SIZE = 1000\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Anonymisation settings\n",
    "PRICE_NOISE_RANGE = (0.95, 1.05)  # ±5% price variation\n",
    "DATE_OFFSET_DAYS = 30  # Max days to shift dates\n",
    "\n",
    "# Columns to drop (based on your original analysis)\n",
    "DROP_COLUMNS = ['Feedback left', 'Feedback received', \n",
    "                'Global Shipping Programme', 'Click and Collect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d02d8",
   "metadata": {},
   "source": [
    "## 3. Load Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407a91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (8778, 14)\n",
      "Columns: ['Sales record number', 'Order number', 'Buyer username', 'Buyer postcode', 'Item number', 'Item title', 'Sold via Promoted listings', 'Quantity', 'Sold for', 'Sale date', 'Feedback left', 'Feedback received', 'Global Shipping Programme', 'Click and Collect']\n",
      "\n",
      "Data types:\n",
      "Sales record number           float64\n",
      "Order number                   object\n",
      "Buyer username                 object\n",
      "Buyer postcode                 object\n",
      "Item number                   float64\n",
      "Item title                     object\n",
      "Sold via Promoted listings     object\n",
      "Quantity                      float64\n",
      "Sold for                       object\n",
      "Sale date                      object\n",
      "Feedback left                  object\n",
      "Feedback received              object\n",
      "Global Shipping Programme      object\n",
      "Click and Collect              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}ebay_march2023_feb2025_less-cols.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e4b71e",
   "metadata": {},
   "source": [
    "## 3.5 Handle eBay's Parent-Child Row Structure\n",
    "\n",
    "eBay exports data with parent rows (order-level) followed by child rows (item-level). Parent rows have missing item details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e582a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structure analysis:\n",
      "Total rows: 8778\n",
      "Rows with missing Item title: 341\n",
      "Percentage of parent rows: 3.9%\n",
      "\n",
      "Example - Order nan:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales record number</th>\n",
       "      <th>Order number</th>\n",
       "      <th>Item title</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sold for</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Sales record number, Order number, Item title, Quantity, Sold for]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for parent rows (missing item details)\n",
    "print(\"Data structure analysis:\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Rows with missing Item title: {df['Item title'].isna().sum()}\")\n",
    "print(f\"Percentage of parent rows: {(df['Item title'].isna().sum() / len(df) * 100):.1f}%\")\n",
    "\n",
    "# Look at example of parent-child structure\n",
    "parent_rows = df[df['Item title'].isna()]\n",
    "if len(parent_rows) > 0:\n",
    "    sample_order = parent_rows.iloc[0]['Order number']\n",
    "    print(f\"\\nExample - Order {sample_order}:\")\n",
    "    display(df[df['Order number'] == sample_order][['Sales record number', 'Order number', 'Item title', 'Quantity', 'Sold for']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d00bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 parent rows (order summaries)\n",
      "Found 8437 child rows (actual items)\n",
      "WARNING: 1 parent rows have missing order numbers - these will be dropped\n",
      "\n",
      "Cleaned dataset: 8437 item-level records\n",
      "Unique orders: 8037\n",
      "\n",
      "First few rows of cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales record number</th>\n",
       "      <th>Order number</th>\n",
       "      <th>Buyer username</th>\n",
       "      <th>Buyer postcode</th>\n",
       "      <th>Item number</th>\n",
       "      <th>Item title</th>\n",
       "      <th>Sold via Promoted listings</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Sold for</th>\n",
       "      <th>Sale date</th>\n",
       "      <th>Feedback left</th>\n",
       "      <th>Feedback received</th>\n",
       "      <th>Global Shipping Programme</th>\n",
       "      <th>Click and Collect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9405.0</td>\n",
       "      <td>08-12772-14508</td>\n",
       "      <td>uk.scooby1</td>\n",
       "      <td>l21 9LX</td>\n",
       "      <td>1.162940e+11</td>\n",
       "      <td>Dr. S. Wong's Sulfur Moisturising Soap 80g - A...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£6.99</td>\n",
       "      <td>28-Feb-25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9404.0</td>\n",
       "      <td>03-12778-00244</td>\n",
       "      <td>hilaridalm-0</td>\n",
       "      <td>BN3 8GG</td>\n",
       "      <td>1.154920e+11</td>\n",
       "      <td>Gluta-C Glutathione &amp; Kojic Plus Acne Control ...</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£8.99</td>\n",
       "      <td>28-Feb-25</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9403.0</td>\n",
       "      <td>11-12768-15354</td>\n",
       "      <td>raconye-82</td>\n",
       "      <td>L36LG</td>\n",
       "      <td>1.155650e+11</td>\n",
       "      <td>Kojie San Soap 100g x 3 (Large Trio Pack) - Sk...</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£8.69</td>\n",
       "      <td>28-Feb-25</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales record number    Order number Buyer username Buyer postcode  \\\n",
       "1               9405.0  08-12772-14508     uk.scooby1        l21 9LX   \n",
       "2               9404.0  03-12778-00244   hilaridalm-0        BN3 8GG   \n",
       "3               9403.0  11-12768-15354     raconye-82          L36LG   \n",
       "\n",
       "    Item number                                         Item title  \\\n",
       "1  1.162940e+11  Dr. S. Wong's Sulfur Moisturising Soap 80g - A...   \n",
       "2  1.154920e+11  Gluta-C Glutathione & Kojic Plus Acne Control ...   \n",
       "3  1.155650e+11  Kojie San Soap 100g x 3 (Large Trio Pack) - Sk...   \n",
       "\n",
       "  Sold via Promoted listings  Quantity Sold for  Sale date Feedback left  \\\n",
       "1                        Yes       1.0   £6.99   28-Feb-25           Yes   \n",
       "2                         No       1.0   £8.99   28-Feb-25            No   \n",
       "3                         No       1.0   £8.69   28-Feb-25            No   \n",
       "\n",
       "  Feedback received Global Shipping Programme Click and Collect  \n",
       "1          positive                        No                No  \n",
       "2               NaN                        No                No  \n",
       "3               NaN                        No                No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell: Code - Fix eBay Parent-Child Structure\n",
    "def fix_ebay_structure(df):\n",
    "    \"\"\"\n",
    "    Fix eBay's parent-child export structure.\n",
    "    Parent rows: Have order info but empty Item number/Item title\n",
    "    Child rows: Have item details\n",
    "    \"\"\"\n",
    "    # Create a copy\n",
    "    df_work = df.copy()\n",
    "    \n",
    "    # Parent rows are those with missing Item title AND Item number\n",
    "    parent_mask = df_work['Item title'].isna() & df_work['Item number'].isna()\n",
    "    parent_rows = df_work[parent_mask]\n",
    "    child_rows = df_work[~parent_mask]\n",
    "    \n",
    "    print(f\"Found {len(parent_rows)} parent rows (order summaries)\")\n",
    "    print(f\"Found {len(child_rows)} child rows (actual items)\")\n",
    "    \n",
    "    # Check for any parent rows with missing order numbers\n",
    "    missing_order = parent_rows['Order number'].isna().sum()\n",
    "    if missing_order > 0:\n",
    "        print(f\"WARNING: {missing_order} parent rows have missing order numbers - these will be dropped\")\n",
    "        parent_rows = parent_rows[parent_rows['Order number'].notna()]\n",
    "    \n",
    "    # For each order, propagate parent row info to children if needed\n",
    "    # (though in your example, child rows seem complete)\n",
    "    \n",
    "    # Simply return child rows since they have all needed info\n",
    "    df_clean = child_rows.copy()\n",
    "    \n",
    "    # Verify the data\n",
    "    print(f\"\\nCleaned dataset: {len(df_clean)} item-level records\")\n",
    "    print(f\"Unique orders: {df_clean['Order number'].nunique()}\")\n",
    "    \n",
    "    # Quick validation - no more missing item titles\n",
    "    assert df_clean['Item title'].notna().all(), \"Still have missing item titles!\"\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Apply the fix\n",
    "df = fix_ebay_structure(df)\n",
    "\n",
    "# Verify\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e4ff9",
   "metadata": {},
   "source": [
    "## 4. Extract Brand Information (for stratified sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae51da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand list\n",
    "BRANDS = [\"Kojie San\", \"Extract\", \"Gluta-C\", \"Silka\", \"Belo\", \n",
    "          \"Maxi-Peel\", \"Likas\", \"GlutaMax\", \"SkinWhite\", \"Glupa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad08b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brand(title):\n",
    "    \"\"\"Extract brand from item title.\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"Other\"\n",
    "    \n",
    "    title_lower = str(title).lower()\n",
    "    for brand in BRANDS:\n",
    "        if brand.lower() in title_lower:\n",
    "            return brand\n",
    "    return \"Other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69df75ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brand distribution:\n",
      "Brand\n",
      "Kojie San    3559\n",
      "Other        1358\n",
      "Extract      1340\n",
      "Silka         705\n",
      "Gluta-C       645\n",
      "Belo          300\n",
      "SkinWhite     161\n",
      "GlutaMax      125\n",
      "Likas         111\n",
      "Maxi-Peel     107\n",
      "Glupa          26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract brand for stratified sampling\n",
    "df['Brand'] = df['Item title'].apply(extract_brand)\n",
    "print(\"\\nBrand distribution:\")\n",
    "print(df['Brand'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48f40b",
   "metadata": {},
   "source": [
    "## 5. Create Stratified Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ccdd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample size: 1000\n",
      "Sample brand distribution:\n",
      "Brand\n",
      "Kojie San    421\n",
      "Other        160\n",
      "Extract      157\n",
      "Silka         83\n",
      "Gluta-C       76\n",
      "Belo          35\n",
      "SkinWhite     19\n",
      "GlutaMax      14\n",
      "Likas         13\n",
      "Maxi-Peel     12\n",
      "Glupa         10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/kfdqhq5j5kq8v8tvtj8qfm6w0000gn/T/ipykernel_72355/3273040689.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample_df = df.groupby('Brand', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling to maintain brand distribution\n",
    "sample_df = df.groupby('Brand', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(len(x), max(10, int(SAMPLE_SIZE * len(x) / len(df)))), \n",
    "                       random_state=RANDOM_STATE)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Ensure we have roughly SAMPLE_SIZE rows\n",
    "if len(sample_df) > SAMPLE_SIZE:\n",
    "    sample_df = sample_df.sample(n=SAMPLE_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\nSample size: {len(sample_df)}\")\n",
    "print(f\"Sample brand distribution:\\n{sample_df['Brand'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec20b9b7",
   "metadata": {},
   "source": [
    "## 6. Anonimise Sensitive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebea4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "anon_df = sample_df.copy()\n",
    "\n",
    "# 1. Anonymise buyer usernames\n",
    "anon_df['Buyer username'] = anon_df['Buyer username'].apply(\n",
    "    lambda x: 'user_' + hashlib.md5(str(x).encode()).hexdigest()[:8] \n",
    "    if pd.notna(x) else 'anonymous'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f049fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generalise postcodes (keep only area)\n",
    "anon_df['Buyer postcode'] = anon_df['Buyer postcode'].apply(\n",
    "    lambda x: str(x).split()[0] if pd.notna(x) and str(x) != 'nan' else 'XX1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e8e5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Anonymise item numbers\n",
    "anon_df['Item number'] = anon_df['Item number'].apply(\n",
    "    lambda x: 'item_' + hashlib.md5(str(x).encode()).hexdigest()[:10]\n",
    "    if pd.notna(x) else 'item_unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d373aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add noise to prices while preserving discount structure\n",
    "def calculate_unit_price(sold_for, quantity):\n",
    "    \"\"\"Calculate original unit price from total after discount.\"\"\"\n",
    "    if quantity == 1:\n",
    "        return sold_for\n",
    "    elif quantity == 2:\n",
    "        return sold_for / (2 * 0.9)\n",
    "    elif quantity == 3:\n",
    "        return sold_for / (3 * 0.85)\n",
    "    else:  # 4+\n",
    "        return sold_for / (quantity * 0.8)\n",
    "    \n",
    "# Extract prices and quantities\n",
    "anon_df['Price_Numeric'] = anon_df['Sold for'].str.replace('£', '').astype(float)\n",
    "\n",
    "# Calculate unit prices\n",
    "anon_df['Unit_Price'] = anon_df.apply(\n",
    "    lambda row: calculate_unit_price(row['Price_Numeric'], row['Quantity']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Add noise to UNIT price (not total)\n",
    "noise = np.random.uniform(0.95, 1.05, len(anon_df))\n",
    "anon_df['Unit_Price_Noisy'] = anon_df['Unit_Price'] * noise\n",
    "\n",
    "# Recalculate total with discount structure\n",
    "def calculate_total_price(unit_price, quantity):\n",
    "    \"\"\"Calculate total price with quantity discounts.\"\"\"\n",
    "    if quantity == 1:\n",
    "        return unit_price\n",
    "    elif quantity == 2:\n",
    "        return unit_price * 2 * 0.9\n",
    "    elif quantity == 3:\n",
    "        return unit_price * 3 * 0.85\n",
    "    else:  # 4+\n",
    "        return unit_price * quantity * 0.8\n",
    "\n",
    "anon_df['Sold for'] = anon_df.apply(\n",
    "    lambda row: f\"£{calculate_total_price(row['Unit_Price_Noisy'], row['Quantity']):.2f}\",\n",
    "    axis=1\n",
    ")\n",
    "    \n",
    "# Clean up temporary columns\n",
    "anon_df = anon_df.drop(columns=['Price_Numeric', 'Unit_Price', 'Unit_Price_Noisy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d59715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymisation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2w/kfdqhq5j5kq8v8tvtj8qfm6w0000gn/T/ipykernel_72355/3681370098.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  anon_df['Sale date'] = pd.to_datetime(anon_df['Sale date'])\n"
     ]
    }
   ],
   "source": [
    "# 5. Shift dates (maintain relative ordering)\n",
    "anon_df['Sale date'] = pd.to_datetime(anon_df['Sale date'])\n",
    "date_offset = np.random.randint(-DATE_OFFSET_DAYS, DATE_OFFSET_DAYS)\n",
    "anon_df['Sale date'] = anon_df['Sale date'] + pd.Timedelta(days=date_offset)\n",
    "anon_df['Sale date'] = anon_df['Sale date'].dt.strftime('%d-%b-%y')\n",
    "\n",
    "print(\"Anonymisation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a3c2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add after calculating unit prices\n",
    "def calculate_discount_percentage(quantity):\n",
    "    \"\"\"Return discount percentage based on quantity.\"\"\"\n",
    "    if quantity == 1:\n",
    "        return 0\n",
    "    elif quantity == 2:\n",
    "        return 10\n",
    "    elif quantity == 3:\n",
    "        return 15\n",
    "    else:  # 4+\n",
    "        return 20\n",
    "\n",
    "anon_df['Discount_Percentage'] = anon_df['Quantity'].apply(calculate_discount_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5e4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    'Face Cream': r'face.*cream|Silka Papaya Day|Gluta-C Facial Face Night',\n",
    "    'Face Wash': r'facial|wash|face',\n",
    "    'Lotion': r'lotion',\n",
    "    'Soap': r'soap',\n",
    "    'Body Washes and Scrubs': r'body wash|scrub|body scrub',\n",
    "    'Toner/Cleanser': r'toner|cleanser|Maxi-Peel Zero',\n",
    "    'Serum': r'serum',\n",
    "    'Shampoo': r'shampoo',\n",
    "    'Conditioner': r'conditioner',\n",
    "    'Powder': r'powder',\n",
    "    'Sensitive Area Products': r'underarm|bikini|gel|roll on|roll-on|deodorant|feminine wash',\n",
    "    'Cologne': r'cologne'\n",
    "}\n",
    "\n",
    "def extract_product_category(title):\n",
    "    \"\"\"Extract general product category from title.\"\"\"\n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Your existing logic\n",
    "    for category, pattern in categories.items():\n",
    "        if re.search(pattern, title_lower):\n",
    "            return category\n",
    "    return \"Other\"\n",
    "\n",
    "def extract_product_size(title):\n",
    "    \"\"\"Extract size information if available.\"\"\"\n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Common size patterns\n",
    "    size_patterns = {\n",
    "        r'(\\d+)\\s*g\\b': 'grams',\n",
    "        r'(\\d+)\\s*ml\\b': 'ml',\n",
    "        r'(\\d+)\\s*oz\\b': 'oz',\n",
    "        r'(\\d+)\\s*pcs?\\b': 'pieces'\n",
    "    }\n",
    "    \n",
    "    for pattern, unit in size_patterns.items():\n",
    "        match = re.search(pattern, title_lower)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}{unit}\"\n",
    "    return \"standard\"\n",
    "\n",
    "# Add to your anonymization\n",
    "anon_df['Product_Category'] = anon_df['Item title'].apply(extract_product_category)\n",
    "anon_df['Product_Size'] = anon_df['Item title'].apply(extract_product_size)\n",
    "anon_df['Discount_Percentage'] = anon_df['Quantity'].apply(calculate_discount_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing bundle vs multipack logic:\n",
      "\n",
      "Extract Papaya Calamansi Soap 6 x 125g BUNDLE\n",
      "  Is Bundle: True, Bundle Qty: 6\n",
      "  Is Multipack: False, Pack Count: 1\n",
      "\n",
      "Kojie San Soap 135g x 2\n",
      "  Is Bundle: False, Bundle Qty: 1\n",
      "  Is Multipack: True, Pack Count: 2\n",
      "\n",
      "Some Bundle Deal 12 x 50g BUNDLE\n",
      "  Is Bundle: True, Bundle Qty: 12\n",
      "  Is Multipack: False, Pack Count: 1\n",
      "\n",
      "Adjusting quantities for bundles...\n"
     ]
    }
   ],
   "source": [
    "# Track Extract bundles as multiple quantities of the same item\n",
    "# This is a specific case where bundles affect quantity, not pack count.\n",
    "# For example, \"Extract Papaya Calamansi Soap 6 x 125g BUNDLE\" means you must buy 6 soaps, not that each pack contains 6 soaps.\n",
    "\n",
    "def extract_product_details(title):\n",
    "    \"\"\"Extract product details - bundles affect quantity, not pack count.\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return {\n",
    "            'Unit_Size': 'unknown',\n",
    "            'Pack_Count': 1,\n",
    "            'Is_Multipack': False,\n",
    "            'Is_Bundle': False,\n",
    "            'Bundle_Qty': 1\n",
    "        }\n",
    "    \n",
    "    title_str = str(title)\n",
    "    title_lower = title_str.lower()\n",
    "    \n",
    "    # Check if it's a bundle\n",
    "    is_bundle = 'bundle' in title_lower\n",
    "    \n",
    "    # Initialize defaults\n",
    "    unit_size = 'unknown'\n",
    "    pack_count = 1  # Default pack count\n",
    "    bundle_qty = 1  # How many items in the bundle\n",
    "    \n",
    "    # For bundles, extract the quantity (e.g., \"6 x 125g BUNDLE\" -> bundle_qty = 6)\n",
    "    if is_bundle:\n",
    "        # Pattern for bundles: \"6 x 125g\"\n",
    "        bundle_pattern = r'(\\d+)\\s*x\\s*(\\d+)\\s*(g|ml|oz)'\n",
    "        match = re.search(bundle_pattern, title_lower)\n",
    "        if match:\n",
    "            bundle_qty = int(match.group(1))  # This is the bundle quantity\n",
    "            unit_size = f\"{match.group(2)}{match.group(3)}\"\n",
    "    \n",
    "    # For multipacks (not bundles), look for \"size x count\" pattern\n",
    "    elif 'x' in title_lower and not is_bundle:\n",
    "        # Pattern: \"135g x 2\" (multipack)\n",
    "        multipack_pattern = r'(\\d+)\\s*(g|ml|oz)\\s*x\\s*(\\d+)'\n",
    "        match = re.search(multipack_pattern, title_lower)\n",
    "        if match:\n",
    "            unit_size = f\"{match.group(1)}{match.group(2)}\"\n",
    "            pack_count = int(match.group(3))  # This is pack count for multipacks\n",
    "    \n",
    "    # Single item pattern\n",
    "    if unit_size == 'unknown':\n",
    "        single_pattern = r'(\\d+)\\s*(g|ml|oz)\\b'\n",
    "        match = re.search(single_pattern, title_lower)\n",
    "        if match:\n",
    "            unit_size = f\"{match.group(1)}{match.group(2)}\"\n",
    "    \n",
    "    is_multipack = (pack_count > 1) and not is_bundle\n",
    "    \n",
    "    return {\n",
    "        'Unit_Size': unit_size,\n",
    "        'Pack_Count': pack_count,\n",
    "        'Is_Multipack': is_multipack,\n",
    "        'Is_Bundle': is_bundle,\n",
    "        'Bundle_Qty': bundle_qty  # How many items must be bought as a bundle\n",
    "    }\n",
    "\n",
    "# Test this understanding\n",
    "test_cases = [\n",
    "    \"Extract Papaya Calamansi Soap 6 x 125g BUNDLE\",  # Bundle: must buy 6\n",
    "    \"Kojie San Soap 135g x 2\",  # Multipack: 1 pack contains 2 soaps\n",
    "    \"Some Bundle Deal 12 x 50g BUNDLE\",  # Bundle: must buy 12\n",
    "]\n",
    "\n",
    "print(\"Testing bundle vs multipack logic:\")\n",
    "for test in test_cases:\n",
    "    result = extract_product_details(test)\n",
    "    print(f\"\\n{test}\")\n",
    "    print(f\"  Is Bundle: {result['Is_Bundle']}, Bundle Qty: {result['Bundle_Qty']}\")\n",
    "    print(f\"  Is Multipack: {result['Is_Multipack']}, Pack Count: {result['Pack_Count']}\")\n",
    "\n",
    "# Now the important part - adjust Quantity for bundles!\n",
    "print(\"\\nAdjusting quantities for bundles...\")\n",
    "\n",
    "# Apply extraction\n",
    "product_details = anon_df['Item title'].apply(extract_product_details)\n",
    "anon_df['Unit_Size'] = product_details.apply(lambda x: x['Unit_Size'])\n",
    "anon_df['Pack_Count'] = product_details.apply(lambda x: x['Pack_Count'])\n",
    "anon_df['Is_Multipack'] = product_details.apply(lambda x: x['Is_Multipack'])\n",
    "anon_df['Is_Bundle'] = product_details.apply(lambda x: x['Is_Bundle'])\n",
    "anon_df['Bundle_Qty'] = product_details.apply(lambda x: x['Bundle_Qty'])\n",
    "\n",
    "# For bundles, the quantity should be the bundle quantity\n",
    "# Save original quantity first\n",
    "anon_df['Original_Quantity'] = anon_df['Quantity']\n",
    "\n",
    "# Update quantity for bundles\n",
    "anon_df.loc[anon_df['Is_Bundle'], 'Quantity'] = anon_df.loc[anon_df['Is_Bundle'], 'Bundle_Qty']\n",
    "\n",
    "# Now calculate total units correctly\n",
    "# For bundles: Bundle_Qty * Original_Quantity (if they bought multiple bundles)\n",
    "# For multipacks: Pack_Count * Quantity\n",
    "# For singles: Quantity\n",
    "anon_df['Total_Units'] = anon_df.apply(\n",
    "    lambda row: row['Bundle_Qty'] * row['Original_Quantity'] if row['Is_Bundle'] \n",
    "    else row['Pack_Count'] * row['Quantity'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af0c5d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced sample dataset saved with 1000 rows and 21 columns\n",
      "Columns: ['Sales record number', 'Order number', 'Buyer username', 'Buyer postcode', 'Item number', 'Item title', 'Sold via Promoted listings', 'Quantity', 'Sold for', 'Sale date', 'Brand', 'Discount_Percentage', 'Product_Category', 'Product_Size', 'Unit_Size', 'Pack_Count', 'Is_Multipack', 'Is_Bundle', 'Bundle_Qty', 'Original_Quantity', 'Total_Units']\n",
      "\n",
      "Sample of anonymised data:\n",
      "    Buyer username                                         Item title  \\\n",
      "521  user_5498d0eb  Kojie San Soap 65g x 3 (Triple Pack) - Skin Br...   \n",
      "941  user_c870a882  Silka Papaya Lotion SPF6 200ml - Skin Lighteni...   \n",
      "741  user_39745765  Dr. Kaufmann Sulfur Soap 80g - Dual Skin Prote...   \n",
      "980  user_f38d6a52  Silka Papaya Lotion SPF6 200ml - Skin Lighteni...   \n",
      "411  user_9608f32f  Kojie San Body Lotion 200g - Lightening & Brig...   \n",
      "\n",
      "     Quantity  Total_Units Sold for  Discount_Percentage  \n",
      "521       1.0          3.0    £6.80                    0  \n",
      "941       1.0          1.0    £9.11                    0  \n",
      "741       2.0          2.0    £6.08                   10  \n",
      "980       1.0          1.0    £9.04                    0  \n",
      "411       1.0          1.0   £13.07                    0  \n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Feedback left', 'Feedback received', \n",
    "                   'Global Shipping Programme', 'Click and Collect']\n",
    "final_df = anon_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Save the enhanced sample dataset\n",
    "final_df.to_csv('../data/sample_data.csv', index=False)\n",
    "print(f\"Enhanced sample dataset saved with {len(final_df)} rows and {len(final_df.columns)} columns\")\n",
    "print(f\"Columns: {final_df.columns.tolist()}\")\n",
    "\n",
    "# Quick validation\n",
    "print(\"\\nSample of anonymised data:\")\n",
    "print(final_df[['Buyer username', 'Item title', 'Quantity', 'Total_Units', 'Sold for', 'Discount_Percentage']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ebay-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
